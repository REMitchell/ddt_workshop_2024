{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01218cc4-6e97-47f4-a162-d2f47c6a7212",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Scrapy (Cheatsheet, not actual Crawler code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc8680-7618-4fe2-ab73-e07e95a57c69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<code>$ scrapy startproject articleSpider</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114dee8-76f8-4640-904e-2bfb1ad8c44a",
   "metadata": {},
   "source": [
    "### Help, I get an error like \"AttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'\"\n",
    "\n",
    "Try:\n",
    "$ pip install cryptography==38.0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e78a4b-a090-4768-82c9-5a170bcc655b",
   "metadata": {},
   "source": [
    "### Help! I get another error\n",
    "\n",
    "Try using conda?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5aaca7-0785-4543-8a59-9e443fae7349",
   "metadata": {},
   "source": [
    "### Directory structure of the articleSpider project looks like this:\n",
    "\n",
    "- scrapy.cfg\n",
    "- articleSpider\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - middlewares.py\n",
    "  - settings.py\n",
    "  - items.py\n",
    "  - pipelines.py\n",
    "  - spiders\n",
    "     - \\_\\_init\\_\\_.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b7001-bfab-4a7c-af23-0681ad8e4c09",
   "metadata": {},
   "source": [
    "<code>$ cd articleSpider</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ded19-9906-482e-a277-4f4b58a1a109",
   "metadata": {},
   "source": [
    "## Generate a basic spider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de36cc-5b8b-43c8-afd0-d218324b2cd7",
   "metadata": {},
   "source": [
    "<code>$ scrapy genspider wikipedia wikipedia.org</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac89e07c-85a9-4c39-89ec-6b7c3c543d9a",
   "metadata": {},
   "source": [
    "Now you have a wikipedia.py file inside your spiders directory! Let's fill out the parse function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca90eb-3b59-4aab-95a8-9be1fd32ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ... \n",
    "def parse(self, response):\n",
    "    soup = BeautifulSoup(response.body, 'html.parser')\n",
    "    print(f'TITLE IS: {soup.title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba35d569-427b-4af3-a6be-68fb99929871",
   "metadata": {},
   "source": [
    "Run with \n",
    "<code>$ scrapy runspider articleSpider/spiders/wikipedia.py</code>\n",
    "and rejoice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f81b9a-eff0-40d9-bc16-679e02be983d",
   "metadata": {},
   "source": [
    "### Help! I get an error like \"MemoryError: Cannot allocate write+execute memory for ffi.callback()\" \n",
    "\n",
    "Try this? Sure, why not.\n",
    "\n",
    "$ pip uninstall cffi\n",
    "\n",
    "$ pip install --upgrade pip \n",
    "\n",
    "$ pip install cffi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf9915-89d8-47b3-88e0-00c6b180ef09",
   "metadata": {},
   "source": [
    "### About the Scrapy Response object (slides)\n",
    "\n",
    "<class 'scrapy.http.response.html.HtmlResponse'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e830ee-68c1-425e-8f3a-379a6b278438",
   "metadata": {},
   "source": [
    "### Scrapy Response Object Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888bae7-4487-4048-b733-5d4f61ca7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Python_(programming_language)\",\n",
    "    \"https://en.wikipedia.org/wiki/Java_(programming_language)\",\n",
    "    \"https://en.wikipedia.org/wiki/Monty_Python\"\n",
    "    ]\n",
    "\n",
    "#...\n",
    "\n",
    "response.css('span.mw-page-title-main::text').extract_first()\n",
    "response.xpath('//span[@class=\"mw-page-title-main\"]//text()').extract()\n",
    "soup = BeautifulSoup(response.body, 'html.parser')\n",
    "print(soup.find('span', {'class': 'mw-page-title-main'}).text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b667b2d-4dff-4198-b013-f576b92dcd80",
   "metadata": {},
   "source": [
    "## Generate a crawler (slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d896cb5-20e7-4c70-bd2d-61a871598ac3",
   "metadata": {},
   "source": [
    "<code>$ scrapy genspider wikipedia2 wikipedia.org -t crawl</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd0496-6383-4749-b82b-c79eb329a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "        Rule(\n",
    "            LinkExtractor(allow='(/wiki/)((?!:).)*$'),\n",
    "            callback='parse',\n",
    "            follow=True,\n",
    "            cb_kwargs={'is_article': True}\n",
    "        ),\n",
    "        Rule(\n",
    "            LinkExtractor(allow='.*'),\n",
    "            callback='parse',\n",
    "            cb_kwargs={'is_article': False}\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ea8e6-551e-4647-bbce-c9a45b4d5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(self, response, is_article):\n",
    "        if not is_article:\n",
    "            print(f'Discarding this: {response.css(\"h1::text\").extract()}')\n",
    "        else:\n",
    "            print(f'VALUABLE CONTENT: {response.css(\"span.mw-page-title-main::text\").extract()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bbb73a-4ced-4235-b62a-3d8f8b007b8f",
   "metadata": {},
   "source": [
    "### Adding Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f1f95-6071-407a-872b-6468caa285b5",
   "metadata": {},
   "source": [
    "items.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a4d0d-b5aa-4dd9-96e8-6dbcf62fcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class ArticlespiderItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    url = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9880e0c-e07c-42b1-88f3-ad5e5e02cfdf",
   "metadata": {},
   "source": [
    "wikipedia2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0751fd5-6ef0-4f83-831b-0718e933797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def parse(self, response, is_article):\n",
    "        if not is_article:\n",
    "            print(f'Discarding this: {response.css(\"h1::text\").extract()}')\n",
    "        else:\n",
    "            article = ArticlespiderItem()\n",
    "            title = response.css(\"span.mw-page-title-main::text\").extract_first()\n",
    "            article['title'] = title\n",
    "            article['url'] = response.url\n",
    "            return article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7aff30-635d-497f-add8-27a0cb59dc78",
   "metadata": {},
   "source": [
    "### Saving your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02c0b8c-2b32-4e15-81ae-e50c41c6bb72",
   "metadata": {},
   "source": [
    "$ scrapy runspider articleSpider/spiders/wikipedia2.py -o articles.csv -t csv\n",
    "\n",
    "$ scrapy runspider articleSpider/spiders/wikipedia2.py -o articles.json -t json\n",
    "\n",
    "$ scrapy runspider articleSpider/spiders/wikipedia2.py -o articles.xml -t xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43c48e-1a3a-4c94-b251-6d66d4a128bb",
   "metadata": {},
   "source": [
    "Note: If you close the spider before it writes the buffer, you're going to get an empty file. Limit the number of pages it scrapes before closing nicely with:\n",
    "-s CLOSESPIDER_PAGECOUNT=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d26786-e7f2-402f-a4d3-4ab67f14e2b4",
   "metadata": {},
   "source": [
    "## Make a cool project! (slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f7d49e-b462-414c-b0c2-4deb6163eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ scrapy genspider wikipedia3 wikipedia.org -t crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04707d9d-6740-4697-b0b1-a6d3bfcd8edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    rules = [\n",
    "        Rule(\n",
    "            LinkExtractor(allow='(/wiki/)((?!:).)*$'),\n",
    "            callback='parse',\n",
    "            follow=True\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb85c8-016e-4815-bfd9-deb31636b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def parse(self, response):\n",
    "        url_title = response.url.split('/')[-1]\n",
    "        history_url = f'https://en.wikipedia.org/w/index.php?title={url_title}&action=history'\n",
    "        yield scrapy.Request(history_url, cb_kwargs={'title': response.css(\"span.mw-page-title-main::text\").extract(), 'language':'en'}, callback=self.parse_history, priority=1)\n",
    "\n",
    "    def parse_history(self, response, **kwargs):\n",
    "        for ip in response.css('.mw-anonuserlink bdi::text').extract():\n",
    "            yield scrapy.Request(f'http://ip-api.com/json/{ip}', cb_kwargs=kwargs, callback=self.parse_ip, priority=2)\n",
    "\n",
    "    def parse_ip(self, response, title=None, language=None):\n",
    "        r = json.loads(response.body)\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235c841-ff1d-4663-8982-e484f7a8c48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
